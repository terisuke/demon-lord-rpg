// src/services/AIVISEnhancedService.ts - P0: å…¨ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°åŒ–
import * as dotenv from 'dotenv';
import { handleError } from '../utils/errorHandler';

// ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºå®Ÿã«èª­ã¿è¾¼ã¿
dotenv.config();
export interface AIVISConfig {
  voice: 'female_calm_jp' | 'male_dramatic_jp' | 'elder_jp' | 'demon_deep_jp';
  speed: number; // 0.8-1.2 based on day tension
  emotion: 'calm' | 'tense' | 'urgent' | 'hope' | 'fear';
  styleId: number;
}

export class AIVISEnhancedService {
  private readonly apiKey: string;
  private readonly baseUrl = 'https://api.aivis-project.com/v1';
  private enabled: boolean = true;
  private currentVolume: number = 0.7;

  constructor() {
    this.apiKey = process.env.AIVIS_API_KEY || '';
    if (!this.apiKey) {
      console.warn('ğŸš¨ AIVIS_API_KEY not found. Audio features will be disabled.');
      this.enabled = false;
    } else {
      console.log(`ğŸµ AIVIS Service åˆæœŸåŒ–æˆåŠŸ (Key: ${this.apiKey.substring(0, 10)}...)`);
    }
  }

  /**
   * P0æ©Ÿèƒ½: ã™ã¹ã¦ã®ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•éŸ³å£°åŒ–
   */
  async synthesizeNarration(
    text: string,
    day: number,
    context: 'narrative' | 'choice' | 'result' | 'npc' = 'narrative'
  ): Promise<string | null> {
    if (!this.enabled || !text.trim()) return null;

    try {
      // Dayåˆ¥æ„Ÿæƒ…ãƒãƒƒãƒ”ãƒ³ã‚°
      const config = this.getVoiceConfigByDay(day, context);

      // Check if models are available
      const modelUuid = this.getModelUuid(config.voice);
      if (!modelUuid) {
        console.warn('ğŸµ AIVIS audio disabled: No available models');
        return null;
      }

      const processedText = this.preprocessText(text);

      const requestBody = {
        model_uuid: modelUuid,
        speaker_uuid: this.getSpeakerUuid(config.voice),
        text: processedText,
        style_id: config.styleId,
        use_ssml: true,
        language: 'ja',
        speaking_rate: config.speed,
        emotional_intensity: this.getEmotionalIntensity(day, context),
        tempo_dynamics: 1.0,
        pitch: 0,
        volume: 1,
        leading_silence_seconds: 0.0, // é«˜é€Ÿå†ç”Ÿé–‹å§‹ã®ãŸã‚
        trailing_silence_seconds: 0.1,
        line_break_silence_seconds: 0.4,
        output_format: 'mp3',
        output_bitrate: 64, // è‰¯å¥½ãªå“è³ªã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ãƒãƒ©ãƒ³ã‚¹
        output_sampling_rate: 22050, // éŸ³å£°å“è³ªå‘ä¸Š
        output_audio_channels: 'mono',
      };

      console.log(`ğŸµ AIVIS API Request:`, {
        url: `${this.baseUrl}/tts/synthesize`,
        model: requestBody.model_uuid,
        speaker: requestBody.speaker_uuid,
        textLength: processedText.length,
        style: requestBody.style_id,
        speaking_rate: requestBody.speaking_rate,
        emotional_intensity: requestBody.emotional_intensity,
      });

      const response = await fetch(`${this.baseUrl}/tts/synthesize`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        let errorDetails = '';
        try {
          const errorBody = await response.text();
          errorDetails = errorBody;
          console.error('ğŸš¨ AIVIS API Error Details:', errorDetails);
        } catch (e) {
          errorDetails = 'ãƒ¬ã‚¹ãƒãƒ³ã‚¹èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼';
        }
        throw new Error(`AIVIS API Error: ${response.status} - ${errorDetails}`);
      }

      // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
      const audioBlob = await response.blob();
      const base64Audio = await this.blobToBase64(audioBlob);

      return base64Audio;
    } catch (error) {
      console.error('[AIVISEnhanced] éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼:', error);
      return null;
    }
  }

  /**
   * Dayé€²è¡Œã«å¿œã˜ãŸéŸ³å£°è¨­å®šã‚’å–å¾—
   */
  private getVoiceConfigByDay(day: number, context: string): AIVISConfig {
    let config: AIVISConfig;

    // åŸºæœ¬è¨­å®š
    if (day <= 10) {
      config = {
        voice: 'female_calm_jp',
        speed: 1.0,
        emotion: 'calm',
        styleId: 0, // ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«
      };
    } else if (day <= 20) {
      config = {
        voice: 'female_calm_jp',
        speed: 1.05,
        emotion: 'tense',
        styleId: 1, // å°‘ã—å¿ƒé…
      };
    } else if (day <= 25) {
      config = {
        voice: 'male_dramatic_jp',
        speed: 1.1,
        emotion: 'urgent',
        styleId: 3, // ç·Šå¼µ
      };
    } else {
      config = {
        voice: 'male_dramatic_jp',
        speed: 1.2,
        emotion: 'fear',
        styleId: 4, // éå¸¸ã«ç·Šè¿«
      };
    }

    // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥èª¿æ•´
    if (context === 'npc') {
      config.voice = 'elder_jp'; // NPCã¯é•·è€ã®å£°
      config.speed = 0.95; // å°‘ã—ã‚†ã£ãã‚Š
    }

    return config;
  }

  /**
   * Dayé€²è¡Œã¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å¿œã˜ãŸæ„Ÿæƒ…å¼·åº¦ã‚’å–å¾—
   */
  private getEmotionalIntensity(day: number, context: string): number {
    let intensity = 1.0; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

    // Dayé€²è¡Œã«ã‚ˆã‚‹æ„Ÿæƒ…å¼·åº¦
    if (day <= 10) {
      intensity = 0.8; // ç©ã‚„ã‹
    } else if (day <= 20) {
      intensity = 1.0; // æ¨™æº–
    } else if (day <= 25) {
      intensity = 1.2; // ã‚„ã‚„ç·Šå¼µ
    } else {
      intensity = 1.5; // éå¸¸ã«ç·Šå¼µ
    }

    // ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¥èª¿æ•´
    switch (context) {
      case 'npc':
        intensity *= 0.9; // NPCã¯å°‘ã—è½ã¡ç€ã„ãŸæ„Ÿã˜
        break;
      case 'choice':
        intensity *= 1.1; // é¸æŠè‚¢ã¯å°‘ã—é‡è¦æ„Ÿã‚’æ¼”å‡º
        break;
      case 'result':
        intensity *= 1.3; // çµæœã¯æ„Ÿæƒ…ã‚’è¾¼ã‚ã¦
        break;
      default: // narrative
        break;
    }

    // æœ€å¤§å€¤åˆ¶é™
    return Math.min(2.0, Math.max(0.5, intensity));
  }

  /**
   * éŸ³å£°ãƒ¢ãƒ‡ãƒ«UUIDå–å¾—ï¼ˆæ­£ç¢ºãªAIVIS API UUIDä½¿ç”¨ï¼‰
   */
  private getModelUuid(_voice: string): string | null {
    // No public models available from AIVIS API - return null to disable audio
    console.warn('ğŸµ No AIVIS models available - audio will be disabled');
    return null;
  }

  /**
   * è©±è€…UUIDå–å¾—
   */
  private getSpeakerUuid(_voice: string): string | null {
    // No public models available from AIVIS API - return null to disable audio
    return null;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†ï¼ˆéŸ³å£°èª­ã¿ä¸Šã’æœ€é©åŒ–ï¼‰
   */
  private preprocessText(text: string): string {
    let processed = text
      .replace(/[ã€Œã€]/g, '') // æ—¥æœ¬èªã‚«ã‚®æ‹¬å¼§ã‚’é™¤å»
      .replace(/ã€[^ã€‘]*ã€‘/g, '') // ã€ã€‘å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰Šé™¤ï¼ˆç‰¹åˆ¥ã‚¤ãƒ™ãƒ³ãƒˆè¡¨ç¤ºãªã©ï¼‰
      .replace(/\.\.\./g, 'ã€') // ä¸‰ç‚¹ãƒªãƒ¼ãƒ€ãƒ¼ã‚’èª­ç‚¹ã«
      .replace(/ï¼/g, 'ã€‚') // æ„Ÿå˜†ç¬¦ã‚’å¥ç‚¹ã«ï¼ˆèª­ã¿ä¸Šã’æ”¹å–„ï¼‰
      .replace(/\s+/g, ' ') // é€£ç¶šç©ºç™½ã‚’å˜ä¸€ç©ºç™½ã«
      .replace(/\n+/g, ' ') // æ”¹è¡Œã‚’ç©ºç™½ã«
      .trim();

    // ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if (!processed) {
      processed = 'ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚';
    }

    // ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ï¼ˆAIVIS APIåˆ¶é™å¯¾ç­–ï¼‰
    if (processed.length > 200) {
      processed = processed.substring(0, 200) + '...';
      console.warn(`âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆã‚’200æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚ã¾ã—ãŸ: "${processed}"`);
    }

    return processed;
  }

  /**
   * Blobã‚’Base64ã«å¤‰æ›
   */
  private async blobToBase64(blob: Blob): Promise<string> {
    try {
      // Node.jsç’°å¢ƒã§ã®Blobâ†’Base64å¤‰æ›
      const arrayBuffer = await blob.arrayBuffer();
      const buffer = Buffer.from(arrayBuffer);
      const base64Data = buffer.toString('base64');

      // data:audio/mp3;base64, ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä»˜ä¸
      return `data:audio/mp3;base64,${base64Data}`;
    } catch (error) {
      throw new Error(`Base64å¤‰æ›ã‚¨ãƒ©ãƒ¼: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * P0æ©Ÿèƒ½: é‡è¦ãªå ´é¢ã§ã®è‡ªå‹•éŸ³å£°åŒ–åˆ¤å®š
   */
  async autoNarrate(
    text: string,
    day: number
  ): Promise<{
    shouldPlay: boolean;
    audioData?: string;
    reason: string;
  }> {
    // é‡è¦åº¦ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    const importance = this.calculateImportance(text, day);

    if (importance < 0.3) {
      return {
        shouldPlay: false,
        reason: `é‡è¦åº¦ä¸è¶³: ${importance.toFixed(2)} < 0.3`,
      };
    }

    const audioData = await this.synthesizeNarration(text, day);

    return {
      shouldPlay: !!audioData,
      audioData: audioData || undefined,
      reason: audioData ? 'éŸ³å£°ç”ŸæˆæˆåŠŸ' : 'éŸ³å£°ç”Ÿæˆå¤±æ•—',
    };
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆé‡è¦åº¦è¨ˆç®—ï¼ˆP0æ©Ÿèƒ½ï¼‰
   */
  private calculateImportance(text: string, day: number): number {
    let score = 0;

    // é•·ã•ã«ã‚ˆã‚‹é‡è¦åº¦
    if (text.length > 50) score += 0.2;
    if (text.length > 100) score += 0.1;

    // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã‚ˆã‚‹é‡è¦åº¦
    const importantKeywords = [
      'é­”ç‹',
      'è¥²æ¥',
      'æ±ºæˆ¦',
      'æœ€å¾Œ',
      'é‹å‘½',
      'æˆ¦ã„',
      'å‹åˆ©',
      'æ•—åŒ—',
      'æ­»',
      'ç”Ÿ',
      'å¸Œæœ›',
      'çµ¶æœ›',
      'æ‘',
      'è‹±é›„',
      'é¸æŠ',
    ];

    for (const keyword of importantKeywords) {
      if (text.includes(keyword)) {
        score += 0.15;
      }
    }

    // Dayé€²è¡Œã«ã‚ˆã‚‹é‡è¦åº¦
    if (day >= 25)
      score += 0.3; // æœ€çµ‚é€±ã¯å…¨ã¦é‡è¦
    else if (day >= 15)
      score += 0.2; // å¾ŒåŠã¯é‡è¦
    else if (day === 1) score += 0.4; // åˆæ—¥ã¯ç‰¹ã«é‡è¦

    // ç‰¹åˆ¥ãªæ—¥ï¼ˆ10æ—¥ã”ã¨ï¼‰ã¯é‡è¦
    if (day % 10 === 0) score += 0.2;

    return Math.min(1.0, score);
  }

  /**
   * NPCã”ã¨ã®éŸ³å£°è¨­å®š
   */
  async speakAsCharacter(character: string, dialogue: string, _day: number): Promise<string | null> {
    if (!this.enabled) return null;

    const characterVoices: Record<
      string,
      { voice: string; styleId: number; emotionalIntensity: number }
    > = {
      Elder_Morgan: { voice: 'elder_jp', styleId: 0, emotionalIntensity: 0.8 },
      Merchant_Gideon: { voice: 'male_dramatic_jp', styleId: 1, emotionalIntensity: 1.2 },
      Guard_Captain: { voice: 'male_dramatic_jp', styleId: 2, emotionalIntensity: 1.3 },
      Demon_Lord: { voice: 'demon_deep_jp', styleId: 4, emotionalIntensity: 1.8 },
      Village_Girl: { voice: 'female_calm_jp', styleId: 0, emotionalIntensity: 0.9 },
    };

    const voiceConfig = characterVoices[character];
    if (!voiceConfig) return null;

    try {
      const requestBody = {
        model_uuid: this.getModelUuid(voiceConfig.voice),
        speaker_uuid: this.getSpeakerUuid(voiceConfig.voice),
        text: this.preprocessText(dialogue),
        style_id: voiceConfig.styleId,
        use_ssml: true,
        language: 'ja',
        speaking_rate: 1.0,
        emotional_intensity: voiceConfig.emotionalIntensity,
        tempo_dynamics: 1.0,
        pitch: 0,
        volume: 1,
        leading_silence_seconds: 0.0,
        trailing_silence_seconds: 0.1,
        line_break_silence_seconds: 0.4,
        output_format: 'mp3',
        output_bitrate: 64,
        output_sampling_rate: 22050,
        output_audio_channels: 'mono',
      };

      const response = await fetch(`${this.baseUrl}/tts/synthesize`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`ğŸš¨ Character voice API error: ${response.status} - ${errorText}`);
        throw new Error(`Character voice error: ${response.status}`);
      }

      const audioBlob = await response.blob();
      return await this.blobToBase64(audioBlob);
    } catch (error) {
      console.error(`[AIVISEnhanced] ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼éŸ³å£°ã‚¨ãƒ©ãƒ¼ (${character}):`, error);
      return null;
    }
  }

  /**
   * ãƒãƒƒãƒå‡¦ç†: è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸¦åˆ—éŸ³å£°åŒ–ï¼ˆPromise.allæº–å‚™ï¼‰
   */
  async synthesizeBatch(
    texts: { text: string; day: number; context?: string }[]
  ): Promise<(string | null)[]> {
    const promises = texts.map(({ text, day, context = 'narrative' }) =>
      this.synthesizeNarration(text, day, context as any)
    );

    try {
      return await Promise.all(promises);
    } catch (error) {
      handleError(error, 'AIVISEnhanced.synthesizeBatch');
      return texts.map(() => null);
    }
  }

  /**
   * éŸ³å£°æ©Ÿèƒ½ON/OFF
   */
  setEnabled(enabled: boolean): void {
    this.enabled = enabled && !!this.apiKey;
    console.log(`[AIVISEnhanced] éŸ³å£°æ©Ÿèƒ½: ${this.enabled ? 'ON' : 'OFF'}`);
  }

  /**
   * ãƒœãƒªãƒ¥ãƒ¼ãƒ èª¿æ•´
   */
  setVolume(volume: number): void {
    this.currentVolume = Math.max(0, Math.min(1, volume));
  }

  /**
   * åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
   */
  async getAvailableModels(): Promise<any> {
    if (!this.enabled) {
      return { error: 'AIVISç„¡åŠ¹' };
    }

    try {
      const response = await fetch(`${this.baseUrl}/aivm-models/search`, {
        headers: {
          Authorization: `Bearer ${this.apiKey}`,
        },
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Model list error: ${response.status} - ${errorText}`);
      }

      const models = await response.json();
      console.log('ğŸµ åˆ©ç”¨å¯èƒ½ãªAIVISãƒ¢ãƒ‡ãƒ«:', models);
      return models;
    } catch (error) {
      console.error('ğŸš¨ AIVISãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
      return { error: error instanceof Error ? error.message : String(error) };
    }
  }

  /**
   * çŠ¶æ…‹å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
   */
  getStatus(): { enabled: boolean; hasApiKey: boolean; volume: number } {
    return {
      enabled: this.enabled,
      hasApiKey: !!this.apiKey,
      volume: this.currentVolume,
    };
  }
}

// ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
export const aivisEnhanced = new AIVISEnhancedService();
